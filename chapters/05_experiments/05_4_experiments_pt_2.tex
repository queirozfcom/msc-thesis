\section{Experiments for Proposal 2}\label{section:experiment_part_2}

\textit{Multi-instance Learning}\footnote{Also called \textit{Multiple-instance} Learning} is a technique (the name was first coined by \cite{dietterich_etal_1997}), whereby a an  instance in a traditional supervised learning problem is split into multiple so-called \textit{bags}.

In other words, each individual sample in a dataset is represented not by a single feature vector but by a set thereof. For example, images may be represented as a bag of patches \citep{maron_ratan_98,andrews_etal_2003}, pharmacological drug molecules may be represented as a bag of configurations \citep{dietterich_etal_1997,andrews_etal_2003}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{chapters/05_experiments/images/miml1.png}
    \caption{Multi-instance learning works by representing a single example as multiple instances.}
    \label{fig:mimlsvm1}
\end{figure}

In 2006, \citeauthor{zhou_zhang_2006} have adapted the multi-instance learning paradigm into the multi-label setting, in the context of \textit{scene classification}. The main insight put forward by this work is that a multi-instance, multi-label (MIML) problem can be transformed into either \textbf{a)} a single-instance, multi-label task or \textbf{b)} a multi-instance, single-label task:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{chapters/05_experiments/images/miml2.png}
    \caption{Original algorithm, devised by \cite{zhou_zhang_2006}, transforms an MIML problem into either a SIML or an MISL problem, using MIMLSVM and MIMLBOOST techniques, respectively.}
    \label{fig:mimlsvm1}
\end{figure}

In 2009, \citeauthor{shen_etal_2009} have applied multi-instance, multi-label (MIML) learning to the tag prediction problem. In particular, they have adapted the MIMLSVM algorithm from \cite{zhou_zhang_2006} to multi-label text classification.

The main idea here is that a single textual document may be split into multiple \textit{segments} via some kind of text segmentation algorithm. This makes it possible to view this problem as a multi-instance, multi-label (MIML) problem, where each segment represents one of many instances for a single document.

Each document is split into segments using a well-known text segmentation algorithm called \textit{TextTiling} (\cite{hearst_1994}). Then, these segments are vectorized into bag-of-words vectors. In order to turn the multiple segments into a single instance, the authors use \textit{k}-medoids clustering based on the Hausdorff distance (\cite{edgar_2008}). Finally, an SVM classifier\footnote{Configured so that it predicts a real-valued score for each tag instead of a binary prediction.} is applied on to the transformed dataset.\\ \\

\begin{algorithm}[H]
\LinesNotNumbered
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{A set $D$ of text documents}
\Output{A trained SVM model to rank tags $y_d$ for every $d$ in $D$}
\BlankLine
 \textbf{Part I: Building a Single-Instance Dataset}
 
\ \ForEach{document $d$ in $D$}{
\BlankLine  
\tcp{split document into segments}\label{cmt}
$segments_d \leftarrow TextTiling(d)$    
  
  \BlankLine
  \BlankLine
  \tcp{transform each segment into a vector of features}\label{cmt} 
  $vectorizedSegments_d \leftarrow extractFeatures(segments_d)$ 
  
  \BlankLine
  \BlankLine
  \tcp{apply $k-$medoids clustering algorithm to the segments of $d$.}\label{cmt}
  \tcp{note that $features_d$ is now a single-instance vector}\label{cmt}
  \tcp{because Hausdorff Distance was used in clustering}\label{cmt}
  $features_d \leftarrow kMedoids( vectorizedSegments_d)$
  \BlankLine
  \BlankLine
  \tcp{this becomes a single row in the new $D'$ dataset}\label{cmt}
  $D'_d \leftarrow features_d$ 
 }
   \BlankLine
  \BlankLine
 \textbf{Part II: Training an SVM Classifier on $D'$}
 \caption{MIMLSVM applied to Tag Prediction \citep{shen_etal_2009} }
\ Train a $Ranked$ SVM algorithm on the transformed features in $D'$
\end{algorithm}

\hfill \break

The objective of the experiments in this section is to ascertain whether (if at all) the original results generalize to other kinds of features.

\subsection{MIMLSVM with IDF weighted Bag-of-words features}

The following is the original version of the MIMLSVM algorithm, i.e. using TF-IDF weighted Bag-of-words features. Values for all hyperparameters were found via grid search on a sample of the full dataset.

\subsubsection{Results on Dataset 1}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/delicious-mimlsvm-tfidf.png}
    \caption{MIMLSVM classifier applied on the Delicious dataset, using TF-IDF weighted bag-of-words features  (validation set scores shown).}
    \label{fig:mimlsvm_delicious_tfidf}
\end{figure}

\subsubsection{Results on Dataset 2}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/mimlsvm-tf-idf-movielens.png}
    \caption{MIMLSVM classifier applied on the Movielens dataset, using TF-IDF weighted bag-of-words features (validation set scores shown).}
    \label{fig:mimlsvm_movielens_tfidf}
\end{figure}

\subsubsection{Discussion}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/proposal-2-compared-1.png}
    \caption{MIMLSVM with TF-IDF features: Compared results (validation set scores)}
    \label{fig:compared_mimlsvm_tfidf}
\end{figure}

Although results for Dataset 1 continue to be better than dataset 2, we notice an interesting development: the difference in scores appears to be smaller than for previous classifiers (i.e. in part 1). We suspect this may be due to the fact that \textit{TextTiling} works by identifying \textit{topics} to split the documents by. 

Dataset 1 is fully composed of actual sentences and phrases, while dataset 2 is made up of HTML source code (albeit with things like tags and javscript code removed). This may have caused the MIMLSVM technique to be better able to extract segment information from the former and not the latter.

Other than that, the results are comparable to those obtained by the original authors.

\subsection{MIMLSVM with LDA Topic Probabilities as Features}

Latent Dirichlet Allocation (LDA) \cite{blei_etal_2003} was originally thought of as an unsupervised method to learn the best way to infer latent topics for documents, based upon the distribution of words in them. 

As mentioned before in section \ref{sub:lda_topics}, the original LDA article itself suggests that topic probabilities be used as features to represent a document. This way, LDA can be thought of as a form of dimensionality reduction for documents, reducing the size of feature vectors from $V$, where $V$ is the size of the vocabulary to $D$, where $D$ is the number of components chosen when training the LDA model.

Each document is therefore represented as a feature vector of size $D$, where each $d_i \in D$ represents how much topic $i$ is present is a document, as per \cite{blei_etal_2003}. Since this vector is a dense vector, it serves out purpose of experimenting on using MIMLSVM on dense document representations.

\subsubsection{Results on Dataset 1}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/delicious-mimlsvm-lda.png}
    \caption{MIMLSVM classifier applied on the Delicious dataset, using LDA topic probabilities as features. (validation set scores shown)}
    \label{fig:mimlsvm_delicious_lda}
\end{figure}

\subsubsection{Results on Dataset 2}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/movielens-mimlsvm-lda.png}
    \caption{MIMLSVM classifier applied on the Movielens dataset, using LDA topic probabilities as features features.}
    \label{fig:movielens_mimlsvm_lda}
\end{figure}

\subsubsection{Discussion}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/proposal-2-compared-2.png}
    \caption{MIMLSVM with LDA features: Compared results (validation set scores)}
    \label{fig:compared_mimlsvm_lda}
\end{figure}

This is the first experiment where we test out our original idea as detailed in proposal 2, namely whether MIMLSVM can generalize with non-sparse, i.e. dense, features.

The results seem to be only very slightly superior to those in the previous experiment using regular bag-of-words features. Initially, it doesn't seem to be the case that using more informative features, with less dimensions makes the prediction task much easier.\footnote{Note that hyperparameters and other choices such as SVM kernels and distance functions were kept the same so as to enable a fair comparison.}

\subsection{MIMLSVM with IDF-weighted Bag-of-embeddings Features}

\subsubsection{Results on dataset 1}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/delicious-mimlsvm-embeddings.png}
    \caption{MIMLSVM classifier applied on the Delicious dataset, using IDF weighted bag-of-embeddings features (validation set scores shown).}
    \label{fig:movielens_mimlsvm_embeddings}
\end{figure}

\subsubsection{Results on Dataset 2}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/movielens-mimlsvm-embeddings.png}
    \caption{MIMLSVM classifier applied on the Movielens dataset, using IDF weighted bag-of-embeddings features (validation set scores shown).}
    \label{fig:movielens_mimlsvm_embeddings}
\end{figure}

\subsubsection{Discussion}

\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{chapters/05_experiments/images/proposal-2-compared-3.png}
    \caption{MIMLSVM with IDF weighted bag-of-embedding features: Compared results (validation set scores)}
    \label{fig:compared_mimlsvm_lda}
\end{figure}

In this case, the switch to IDF-weighted bag-of-embeddings decreased classifier accuracy by a significant amount.

\subsection{Final Results and discussion}\label{sub:final_results_prop_2}

\begin{figure}[H]
    \begin{subfigure}{0.5\textwidth}
        \centering
    \includegraphics[width=0.8\textwidth]{chapters/05_experiments/images/proposal-2-compared-delicious.png}
    \caption{Full comparison of all MIMLSVM variants used on dataset 1: Delicious T-140.}
    \label{fig:full_comparison_dataset_1}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \centering
    \includegraphics[width=0.8\textwidth]{chapters/05_experiments/images/proposal-2-compared-movielens.png}
    \caption{Full comparison of all MIMLSVM variants used on dataset 2: Moivelens+IMDB.}
    \label{fig:full_comparison_dataset_2}
    \end{subfigure}
    \caption{Full comparison of all techniques used for proposal 2 (validation set scores).}
\end{figure}

After conducting these experiments, it does look like the MIMLSVM algorithm can indeed be used for dense text representations, in both \textit{well-structured} text with phrases and sentences as in dataset 1 and in looser, more unstructured text as in dataset 2.

Apparently the variant using LDA topic probabilities as features had a small but noticeable advantage over other cases for dataset 1, but not for dataset 2.

On the other hand, the variant using IDF-weighted bag-of-embeddings performed clearly worse in both cases.